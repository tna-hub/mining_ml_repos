

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Documentation &mdash; sequence-to-sequence-from-scratch 1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Recommended Readings" href="recommendedreading.html" />
    <link rel="prev" title="Welcome to Sequence to Sequence from Scratch!" href="../index.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Content</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#sequence-to-sequence-modeling">Sequence to Sequence Modeling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#what-is-the-problem">What is the problem?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#what-makes-the-problem-a-problem">What makes the problem a problem?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#what-is-the-secret-sauce-here">What is the secret sauce here?</a></li>
<li class="toctree-l3"><a class="reference internal" href="#who-cares">Who cares?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#model">Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#word-embedding">Word Embedding</a></li>
<li class="toctree-l3"><a class="reference internal" href="#encoder">Encoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#decoder">Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="#encoder-decoder-bridge">Encoder-Decoder Bridge</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dataset">Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="#training-evaluation">Training/Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#results">Results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="recommendedreading.html">Recommended Readings</a></li>
</ul>
<p class="caption"><span class="caption-text">Document Credentials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../credentials/CONTRIBUTING.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../credentials/CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../credentials/LICENSE.html">LICENSE</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">sequence-to-sequence-from-scratch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Documentation</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="documentation">
<h1>Documentation<a class="headerlink" href="#documentation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="sequence-to-sequence-modeling">
<h2>Sequence to Sequence Modeling<a class="headerlink" href="#sequence-to-sequence-modeling" title="Permalink to this headline">¶</a></h2>
<p>In this project we explain the sequence to sequence modeling using [<a class="reference external" href="https://pytorch.org/">Pytorch</a>].</p>
<div class="section" id="what-is-the-problem">
<h3>What is the problem?<a class="headerlink" href="#what-is-the-problem" title="Permalink to this headline">¶</a></h3>
<p>Machine Translation(MT) is one of the areas of NLP that has been profoundly affected by advances in deep learning.
In fact, progress in MT can be categorized into pre-deep learning and deep learning era. Confirmation of this could
be some of the reference books in NLP community such as ”Speech and Language Processing”. Second version of
this book was published in 2008 and chapter 25 is dedicated to machine translation but there is not a single mention of
deep learning usage for MT. However, today we know that the top performing machine translation systems are solely
based on neural networks which led to the term Neural Machine Translation (NMT).</p>
<p>When we use the term neural machine translation, we are talking about applying different deep learning tech-
niques for the task of machine translation. It was after success of neural network in image classification tasks
that researchers started to use neural networks in machine translation. Around 2013 research groups started to achieve
breakthrough results in NMT and boosted state of the art performance. Unlike traditional statistical machine transla-
tion, NMT is based on an end-to-end neural network that increases the performance of machine translation systems.</p>
<p>We dedicate this project to a core deep learning based model for sequence-to-sequence modeling and in particular machine translation: An Encoder-Decoder architecture
based on Long-Short Term Memory (LSTM) networks.</p>
</div>
<div class="section" id="what-makes-the-problem-a-problem">
<h3>What makes the problem a problem?<a class="headerlink" href="#what-makes-the-problem-a-problem" title="Permalink to this headline">¶</a></h3>
<p>Although sequence to sequence modeling scope is broader than just the machine translation task,
the main focus on seq-2-seq research has been dedicated to MT due to its great importance in real-world
problems. Furthermore, machine translation is the bridge for a universal human-machine conversation.</p>
</div>
<div class="section" id="what-is-the-secret-sauce-here">
<h3>What is the secret sauce here?<a class="headerlink" href="#what-is-the-secret-sauce-here" title="Permalink to this headline">¶</a></h3>
<p>Here, we tried to achieve some primary goals as we hope to make this work unique compared to the many other available tutorials:</p>
<blockquote>
<div><p>1. We called this repo <code class="docutils literal notranslate"><span class="pre">&quot;from</span> <span class="pre">scratch&quot;</span></code> due to the fact that we do NOT consider
any background for the reader in terms of implementation.</p>
<p>2. Instead of using high-level package modules,
simple RNN architectures are used for demonstration purposes.
This helps the reader to <code class="docutils literal notranslate"><span class="pre">understand</span> <span class="pre">everything</span> <span class="pre">from</span> <span class="pre">scratch</span></code>.
The downside, however, is the relatively low speed of training.
This may not cause any trouble as we try to train a very small model.</p>
<p>3. The difference between <code class="docutils literal notranslate"><span class="pre">uni-directional</span> <span class="pre">LSTMs</span></code> and <code class="docutils literal notranslate"><span class="pre">bi-directional</span> <span class="pre">LSTMs</span></code>
have been clarified using the simple encoder-decoder implementation.</p>
</div></blockquote>
</div>
<div class="section" id="who-cares">
<h3>Who cares?<a class="headerlink" href="#who-cares" title="Permalink to this headline">¶</a></h3>
<p>It tutorial has been provided for the developers/researchers who really want
to start from scratch and learn everything <code class="docutils literal notranslate"><span class="pre">spoon-by-spoon</span></code>. The goal is to
give as much detail as possible so the others do NOT have to spend the time to
understand hidden and yet very important details.</p>
</div>
</div>
<div class="section" id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h2>
<p>The goal here is to create a <strong>sequence-to-sequence mapping</strong> model which is going to be built on an
Encoder-Decoder network. The model encode the information into a specific representation. This representation
later on will be mapped as a target output sequence. This transition makes the model understand the interoperibility
between two sequences. In another word, the meaningful connection between the two sequence will be created. Two important
sequence to sequence modeling examples are <code class="docutils literal notranslate"><span class="pre">Machine</span> <span class="pre">Transtional</span></code> and <code class="docutils literal notranslate"><span class="pre">Autoencoders</span></code>. Here, we can do both just by
chaning the <code class="docutils literal notranslate"><span class="pre">input-output</span></code> language sequences.</p>
<div class="section" id="word-embedding">
<h3>Word Embedding<a class="headerlink" href="#word-embedding" title="Permalink to this headline">¶</a></h3>
<p>At the very first step, we should know what are the <code class="docutils literal notranslate"><span class="pre">input-output</span> <span class="pre">sequences</span></code> and how we should <code class="docutils literal notranslate"><span class="pre">represent</span> <span class="pre">the</span> <span class="pre">data</span></code>
for the model to understand it. Clearly, it should be a sequence of words in the input and the equivalent
sequence in the output. In case of having an autoencoder, both input and output sentences
are the same.</p>
<p>A learned representation for context elements is called <code class="docutils literal notranslate"><span class="pre">word</span> <span class="pre">embedding</span></code> in which the words with similar meaning, ideally,
become highly correlated in the representation space as well. One of the main incentives behind word embedding representations
is the high generalization power as opposed to sparse higher dimensional representation. Unlike the traditional
bag-of-word representation in which different words have quite different representation regardless of their usage,
in learning the distributed representation, the usage of words in the context is of great importance which lead to
similar representation for correlated words in meaning. The are different approaches for creating word embedding. Please
refer to the great Pytorch tutorial titled [<a class="reference external" href="https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html">WORD EMBEDDINGS: ENCODING LEXICAL SEMANTICS</a>]
for more details.</p>
</div>
<div class="section" id="encoder">
<h3>Encoder<a class="headerlink" href="#encoder" title="Permalink to this headline">¶</a></h3>
<p>The encoder generates a single output vector that embodies the input sequence meaning. The general procedure is as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li>In each step, a word will be fed to a network and it generates an output and a hidden state.</li>
<li>For the next step, the hidden step and the next word will be fed to the same network (W) for updating the weights.</li>
<li>In the end, the last output will be the representative of the input sentence (called the “context vector”).</li>
</ol>
</div></blockquote>
<p>The <code class="docutils literal notranslate"><span class="pre">EncoderRNN</span></code> attribute is dedicated to the encoder structure. The Encoder in our code,
can be a <code class="docutils literal notranslate"><span class="pre">unidirectional/bidirectional</span> <span class="pre">LSTM</span></code>. A <em>Bidirectional</em> LSTM consists of <em>two
independent LSTMs</em>, one take the input sequence in normal time order and the other one
will be fed with the input sequence in the reverse time order. The outputs of the two
will usually be concatenated at each time step (usually the <em>last hidden states</em> will be concatenated
and returned). The created feature vector will represents the initial hidden states of the decoder. The
architecture of a bi-lstm is as below:</p>
<div class="figure">
<a class="reference internal image-reference" href="../_images/bilstm.png"><img alt="map to buried treasure" src="../_images/bilstm.png" style="width: 600.0px; height: 377.0px;" /></a>
</div>
<p><strong>NOTE:</strong> As can be observered in the figure <em>colors</em>, two <code class="docutils literal notranslate"><span class="pre">independent</span></code> different set of
weights <code class="docutils literal notranslate"><span class="pre">MUST</span></code> be considered for the forward and backward passes, Otherwise, the network will
assume the backward pass follows the forward pass!!</p>
<p>The encoder, will generally be initialized as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
   <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">   * For nn.LSTM, same input_size &amp; hidden_size is chosen.</span>
<span class="sd">   :param input_size: The size of the input vocabulary</span>
<span class="sd">   :param hidden_size: The hidden size of the RNN.</span>
<span class="sd">   :param batch_size: The batch_size for mini-batch optimization.</span>
<span class="sd">   :param num_layers: Number of RNN layers. Default: 1</span>
<span class="sd">   :param bidirectional: If the encoder is a bi-directional LSTM. Default: False</span>
<span class="sd">   &quot;&quot;&quot;</span>
   <span class="nb">super</span><span class="p">(</span><span class="n">EncoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
   <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
   <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
   <span class="bp">self</span><span class="o">.</span><span class="n">bidirectional</span> <span class="o">=</span> <span class="n">bidirectional</span>
   <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

   <span class="c1"># The input should be transformed to a vector that can be fed to the network.</span>
   <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span>

   <span class="c1"># The LSTM layer for the input</span>
   <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>NOTE:</strong> We <code class="docutils literal notranslate"><span class="pre">do</span> <span class="pre">NOT</span></code> generate the whole LSTM/Bi-LSTM architecture using Pytorch. Instead, we just use
the LSTM cells to represent <strong>what exactly is going on in the encoding/decoding</strong> phases!</p>
<p>The initialization of the LSTM is a little bit different compared to the LSTM
[<a class="reference external" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Netwroks</a>].
Both cell state and hidden states must be initialized as belows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
      <span class="n">encoder_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)]</span>
      <span class="n">encoder_state</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;forward&quot;</span><span class="p">:</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="s2">&quot;backward&quot;</span><span class="p">:</span> <span class="n">encoder_state</span><span class="p">}</span>
      <span class="k">return</span> <span class="n">encoder_state</span>
  <span class="k">else</span><span class="p">:</span>
      <span class="n">encoder_state</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)]</span>
      <span class="k">return</span> <span class="n">encoder_state</span>
</pre></div>
</div>
<p>As it can be seen in the above code, for the <em>Bidirectional LSTM</em>, we have <strong>separate and independent</strong>
states for <code class="docutils literal notranslate"><span class="pre">forwards</span></code> and <code class="docutils literal notranslate"><span class="pre">backward</span></code> directions.</p>
</div>
<div class="section" id="decoder">
<h3>Decoder<a class="headerlink" href="#decoder" title="Permalink to this headline">¶</a></h3>
<p>For the decoder, the final encoder hidden state (or the concatenation if we have a bi-lstm as the encoder)
of the encoder will be called <code class="docutils literal notranslate"><span class="pre">context</span> <span class="pre">vector</span></code>. This context vector, generated by the encoder, will
be used as the initial hidden state of the decoder. Decoding is as follows:</p>
<blockquote>
<div><ol class="arabic">
<li><p class="first">At each step, an input token and a hidden state is fed to the decoder.</p>
<blockquote>
<div><ul class="simple">
<li>The initial input token is the <code class="docutils literal notranslate"><span class="pre">&lt;SOS&gt;</span></code>.</li>
<li>The first hidden state is the context vector generated by the encoder (the encoder’s last hidden state).</li>
</ul>
</div></blockquote>
</li>
<li><p class="first">The first output, should be the first word of the output sequence and so on.</p>
</li>
<li><p class="first">The output token generation ends with <code class="docutils literal notranslate"><span class="pre">&lt;EOS&gt;</span></code> being generated or the predefined max_length of the output sentence.</p>
</li>
</ol>
</div></blockquote>
<p>After the first decoder step, for the following steps, the input is going to be the previous word prediction of the RNN.
So the output generation will be upon the network sequence prediction. In case of using <code class="docutils literal notranslate"><span class="pre">teacher_forcing</span></code>, the input is going to be the actual
targeted output word. It provides better guidance for the training but it is inconsistent with the evaluation stage as
targeted outputs do not exists! In order to handle the issue with this approach, new approaches have been proposed.</p>
<p>The decoder, will generally be initialized as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">DecoderRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">output_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">h_n</span><span class="p">,</span> <span class="n">c_n</span><span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">h_n</span><span class="p">,</span> <span class="n">c_n</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">initHidden</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The spesific type of the hidden layer for the RNN type that is used (LSTM).</span>
<span class="sd">    :return: All zero hidden state.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)]</span>
</pre></div>
</div>
</div>
<div class="section" id="encoder-decoder-bridge">
<h3>Encoder-Decoder Bridge<a class="headerlink" href="#encoder-decoder-bridge" title="Permalink to this headline">¶</a></h3>
<p>The context vector, generated by the encoder, will be used as the initial hidden state of the decoder.
In case that their <em>dimension is not matched</em>, a <code class="docutils literal notranslate"><span class="pre">linear</span> <span class="pre">layer</span></code> should be employed to transformed the context vector
to a suitable input (shape-wise) for the decoder cell state (including the memory(Cn) and hidden(hn) states).
The shape mismatch is True in the following conditions:</p>
<blockquote>
<div><ol class="arabic simple">
<li>The hidden sizes of encoder and decoder are the same BUT we have a bidirectional LSTM as the Encoder.</li>
<li>The hidden sizes of encoder and decoder are NOT same.</li>
<li>ETC?</li>
</ol>
</div></blockquote>
<p>The linear layer will be defined as below:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">hidden_size_encoder</span><span class="p">,</span> <span class="n">hidden_size_decoder</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Linear</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bidirectional</span> <span class="o">=</span> <span class="n">bidirectional</span>
    <span class="n">num_directions</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">bidirectional</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear_connection_op</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_directions</span> <span class="o">*</span> <span class="n">hidden_size_encoder</span><span class="p">,</span> <span class="n">hidden_size_decoder</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">connection_possibility_status</span> <span class="o">=</span> <span class="n">num_directions</span> <span class="o">*</span> <span class="n">hidden_size_encoder</span> <span class="o">==</span> <span class="n">hidden_size_decoder</span>

<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">connection_possibility_status</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">input</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_connection_op</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<p><strong>NOTE:</strong> The dataset object is heavily inspired by the official Pytorch tutorial: [<a class="reference external" href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html/">TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION</a>]
The dataset is prepaired using the <code class="docutils literal notranslate"><span class="pre">data_loader.py</span></code> script.</p>
<p>At the first state we have to define <code class="docutils literal notranslate"><span class="pre">word</span> <span class="pre">indexing</span></code> for further processing. The <code class="docutils literal notranslate"><span class="pre">word2index</span></code> is the dictionary of
transforming word to its associated index and <code class="docutils literal notranslate"><span class="pre">index2word</span></code> does the reverse:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SOS_token</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">EOS_token</span> <span class="o">=</span> <span class="mi">2</span>

<span class="k">class</span> <span class="nc">Lang</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span> <span class="o">=</span> <span class="p">{}</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span> <span class="o">=</span> <span class="p">{}</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">,</span> <span class="n">SOS_token</span><span class="p">:</span> <span class="s2">&quot;SOS&quot;</span><span class="p">,</span> <span class="n">EOS_token</span><span class="p">:</span> <span class="s2">&quot;EOS&quot;</span><span class="p">}</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># Count SOS and EOS</span>

  <span class="k">def</span> <span class="nf">addSentence</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">addWord</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">addWord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">word</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">word2index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">index2word</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">n_words</span><span class="p">]</span> <span class="o">=</span> <span class="n">word</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">n_words</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">else</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">word2count</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Unlike the [<a class="reference external" href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html/">Pytorch tutorial</a>] we started
the indexing from <code class="docutils literal notranslate"><span class="pre">1</span></code> by <code class="docutils literal notranslate"><span class="pre">SOS_token</span> <span class="pre">=</span> <span class="pre">1</span></code> to have the <code class="docutils literal notranslate"><span class="pre">zero</span> <span class="pre">reserved</span></code>!</p>
<p>In the end, we define a dataset class to handle the processing:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Dataset</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;dataset object&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">num_embeddings</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">max_input_length</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">auto_encoder</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The initialization of the dataset object.</span>
<span class="sd">        :param phase: train/test.</span>
<span class="sd">        :param num_embeddings: The embedding dimentionality.</span>
<span class="sd">        :param max_input_length: The maximum enforced length of the sentences.</span>
<span class="sd">        :param transform: Post processing if necessary.</span>
<span class="sd">        :param auto_encoder: If we are training an autoencoder or not.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">auto_encoder</span><span class="p">:</span>
            <span class="n">lang_in</span> <span class="o">=</span> <span class="s1">&#39;eng&#39;</span>
            <span class="n">lang_out</span> <span class="o">=</span> <span class="s1">&#39;eng&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lang_in</span> <span class="o">=</span> <span class="s1">&#39;eng&#39;</span>
            <span class="n">lang_out</span> <span class="o">=</span> <span class="s1">&#39;fra&#39;</span>
        <span class="c1"># Skip and eliminate the sentences with a length larger than max_input_length!</span>
        <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">pairs</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span><span class="n">lang_in</span><span class="p">,</span> <span class="n">lang_out</span><span class="p">,</span> <span class="n">max_input_length</span><span class="p">,</span> <span class="n">auto_encoder</span><span class="o">=</span><span class="n">auto_encoder</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">pairs</span><span class="p">))</span>

        <span class="c1"># Randomize list</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">pairs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
            <span class="n">selected_pairs</span> <span class="o">=</span> <span class="n">pairs</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">))]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">selected_pairs</span> <span class="o">=</span> <span class="n">pairs</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="mf">0.8</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">pairs</span><span class="p">)):]</span>

        <span class="c1"># Getting the tensors</span>
        <span class="n">selected_pairs_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensorsFromPair</span><span class="p">(</span><span class="n">selected_pairs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">input_lang</span><span class="p">,</span> <span class="n">output_lang</span><span class="p">,</span> <span class="n">max_input_length</span><span class="p">)</span>
                     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">selected_pairs</span><span class="p">))]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_embeddings</span> <span class="o">=</span> <span class="n">num_embeddings</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_input_length</span> <span class="o">=</span> <span class="n">max_input_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">selected_pairs_tensors</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_lang</span> <span class="o">=</span> <span class="n">input_lang</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_lang</span> <span class="o">=</span> <span class="n">output_lang</span>
</pre></div>
</div>
</div>
<div class="section" id="training-evaluation">
<h2>Training/Evaluation<a class="headerlink" href="#training-evaluation" title="Permalink to this headline">¶</a></h2>
<p>The training/evaluation of this model is done in a not very optimized way deliberately!! The reasons are as follows:</p>
<blockquote>
<div><p>1. I followed the principle of <code class="docutils literal notranslate"><span class="pre">running</span> <span class="pre">with</span> <span class="pre">one</span> <span class="pre">click</span></code> that I personnal have for all my open source projects.
The principle says: “Everyone must be able to run everything by one click!”. So you see pretty much everything in one
Python file!</p>
<p>2. Instead of using ready-to-use RNN objects which process mini-batches of data, we input the sequence word-by-word to help
the readers having a better sense of what is happening behind the doors of seq-to-seq modeling scheme.</p>
<p>3. For the evaluation, we simply generate the outputs of
the system based on the built model to see if the model is good enough!</p>
</div></blockquote>
<p>For mini-batch optimization, we input batches of sequences. There is a very important note for the batch feeding. After
inputing each batch element, the <code class="docutils literal notranslate"><span class="pre">encoder</span> <span class="pre">hidden</span> <span class="pre">states</span></code> must be reset. Otherwise, the system may assume the next sequence in a batch follows
the previously processed sequence. It can be seen in the following Python script:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">step_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
  <span class="c1"># reset the LSTM hidden state. Must be done before you run a new sequence. Otherwise the LSTM will treat</span>
  <span class="c1"># the new input sequence as a continuation of the previous sequence.</span>
  <span class="n">encoder_hidden</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">initHidden</span><span class="p">()</span>
  <span class="n">input_tensor_step</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="p">[:,</span> <span class="n">step_idx</span><span class="p">][</span><span class="n">input_tensor</span><span class="p">[:,</span> <span class="n">step_idx</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span>
  <span class="n">input_length</span> <span class="o">=</span> <span class="n">input_tensor_step</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h2>
<p>Some sample results for autoencoder training are as follows:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">Input:  you re very generous  EOS</span>
<span class="go">Output:  you re very generous  EOS</span>
<span class="go">Predicted Output:  you re very generous  &lt;EOS&gt;</span>

<span class="go">Input:  i m worried about the future  EOS</span>
<span class="go">Output:  i m worried about the future  EOS</span>
<span class="go">Predicted Output:  i m worried about the about  &lt;EOS&gt;</span>

<span class="go">Input:  we re anxious  EOS</span>
<span class="go">Output:  we re anxious  EOS</span>
<span class="go">Predicted Output:  we re anxious  &lt;EOS&gt;</span>

<span class="go">Input:  she is more wise than clever  EOS</span>
<span class="go">Output:  she is more wise than clever  EOS</span>
<span class="go">Predicted Output:  she is nothing than a than  &lt;EOS&gt;</span>

<span class="go">Input:  i m glad i invited you  EOS</span>
<span class="go">Output:  i m glad i invited you  EOS</span>
<span class="go">Predicted Output:  i m glad i invited you  &lt;EOS&gt;</span>
</pre></div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="recommendedreading.html" class="btn btn-neutral float-right" title="Recommended Readings" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral" title="Welcome to Sequence to Sequence from Scratch!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Amirsina Torfi
      Last updated on True.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript">
          var DOCUMENTATION_OPTIONS = {
              URL_ROOT:'../',
              VERSION:'1.0',
              LANGUAGE:'en',
              COLLAPSE_INDEX:false,
              FILE_SUFFIX:'.html',
              HAS_SOURCE:  true,
              SOURCELINK_SUFFIX: '.txt'
          };
      </script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
    

  

  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>